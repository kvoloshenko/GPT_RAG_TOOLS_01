{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3zhqjRUXnwg"
      },
      "source": [
        "# Приложение Flask для запроса ChatGPT\n",
        "\n",
        "Flask application for ChatGPT request\n",
        "\n",
        "\n",
        "\n",
        "Приглашаю в Телеграм общаться по это теме: https://t.me/AiExp01"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Сохраняйте эту ячейку активной, чтобы Colab не отключил вас. { display-mode: \"form\" }\n",
        "\n",
        "#@markdown Нажмите кнопку воспроизведения на музыкальном проигрывателе, который появится ниже:\n",
        "%%html\n",
        "<audio src=\"https://oobabooga.github.io/silence.m4a\" controls>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "h_5yM3edy3I0",
        "outputId": "f06cf3e7-80e1-4544-f5c2-e177ceedf9d6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<audio src=\"https://oobabooga.github.io/silence.m4a\" controls>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQY3QP0dD260"
      },
      "outputs": [],
      "source": [
        "!pip -q install pyngrok\n",
        "!pip -q install openai\n",
        "!pip -q install loguru\n",
        "!pip -q install tiktoken\n",
        "!pip -q install langchain\n",
        "!pip -q install langchain-openai\n",
        "# !pip -q install faiss-cpu\n",
        "!pip -q install faiss-gpu\n",
        "!pip -q install langchain-community\n",
        "!git clone https://github.com/kvoloshenko/GPT_RAG_TOOLS_01.git\n",
        "%cd /content/GPT_RAG_TOOLS_01/Python\n",
        "# from tools_01 import get_google_url\n",
        "import tools_01 as tls\n",
        "import db_tools_01 as dbt\n",
        "import gpt_tools_01 as gpt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Подключаем Google disk\n",
        "# для этого необходима учетная запись на гугл\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "04HslIe4VkAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwyFhK5pJtBK"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, request, json\n",
        "from werkzeug.utils import secure_filename\n",
        "from pyngrok import ngrok\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "import os\n",
        "from loguru import logger\n",
        "\n",
        "DB_DIR_NAME = '/content/drive/MyDrive/_AI/Db/'\n",
        "CHUNK_SIZE = 1024\n",
        "NUMBER_RELEVANT_CHUNKS = 5\n",
        "TEMPERATURE = 0.8            # Температура модели\n",
        "LL_MODEL = \"gpt-3.5-turbo-0613\" # Модель\n",
        "\n",
        "logger.add(\"/content/drive/MyDrive/_AI/Logs/bot_debug.log\", format=\"{time} {level} {message}\", level=\"DEBUG\", rotation=\"100 KB\", compression=\"zip\")\n",
        "\n",
        "\n",
        "# Установка Ngrok_API_KEY\n",
        "Ngrok_API_KEY=userdata.get('Ngrok_API_KEY')\n",
        "ngrok.set_auth_token(Ngrok_API_KEY)\n",
        "\n",
        "# Установка OpenAI API key\n",
        "OpenAI_API_KEY=userdata.get('OpenAI_API_KEY')\n",
        "os.environ[\"OPENAI_API_KEY\"] = OpenAI_API_KEY\n",
        "\n",
        "# LL_MODEL = \"gpt-4-0613\"\n",
        "LL_MODEL = \"gpt-3.5-turbo\"\n",
        "print(f'LL_MODEL = {LL_MODEL}')\n",
        "client = OpenAI(\n",
        "    api_key=OpenAI_API_KEY\n",
        ")\n",
        "port_no = 5000\n",
        "app = Flask(__name__)\n",
        "\n",
        "public_url =  ngrok.connect(port_no).public_url\n",
        "print(f\"To acces the Gloable link please click {public_url}\")\n",
        "tls.write_to_file(public_url, \"/content/drive/MyDrive/_AI/Db/public_url.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "x_aHj0gzP2gr"
      },
      "outputs": [],
      "source": [
        "# Функции для Flask\n",
        "UPLOAD_FOLDER = '/content/sample_data'\n",
        "ALLOWED_EXTENSIONS = {'wav'}\n",
        "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
        "\n",
        "def allowed_file(filename):\n",
        "    return '.' in filename and \\\n",
        "           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return f\"Running Flask on Google Colab!\"\n",
        "\n",
        "@app.route('/chat', methods=['POST'])\n",
        "def chat():\n",
        "    data = json.loads(request.data)\n",
        "    print(type(data), f'chat data={data}')\n",
        "    system_content = data['system_content']\n",
        "    user_content = data['user_content']\n",
        "    completion = gpt.get_simple_answer_gpt(system_content, user_content, LL_MODEL, TEMPERATURE, client)\n",
        "    answer = completion.choices[0].message.content\n",
        "    data['answer'] = answer\n",
        "    print(f'return data={data}')\n",
        "    return data\n",
        "\n",
        "@app.route('/answer_gpt', methods=['POST'])\n",
        "def answer_gpt():\n",
        "    data = json.loads(request.data)\n",
        "    print(type(data), f'chat data={data}')\n",
        "    system_content = data['system_content']\n",
        "    user_content = data['user_content']\n",
        "    ba = data['ba']\n",
        "    answer = gpt.get_answer_gpt(system_content, user_content, ba, LL_MODEL, TEMPERATURE, NUMBER_RELEVANT_CHUNKS, DB_DIR_NAME, client)\n",
        "    data['answer'] = answer\n",
        "    print(f'return data={data}')\n",
        "    return data\n",
        "\n",
        "\n",
        "@app.route('/transcript', methods=['POST'])\n",
        "# https://flask.palletsprojects.com/en/2.3.x/patterns/fileuploads/\n",
        "def transcript():\n",
        "    logger.debug(\"transcript\")\n",
        "\n",
        "    # check if the post request has the file part\n",
        "    if 'file' not in request.files:\n",
        "        flash('No file part')\n",
        "        return 'No file part'\n",
        "    file = request.files['file']\n",
        "    logger.debug(type(file))\n",
        "    args = request.args\n",
        "    language = request.args.get('language')\n",
        "    # If the user does not select a file, the browser submits an\n",
        "    # empty file without a filename.\n",
        "    if file.filename == '':\n",
        "        flash('No selected file')\n",
        "        return 'No file part'\n",
        "    if file and allowed_file(file.filename):\n",
        "        filename = secure_filename(file.filename)\n",
        "        file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))\n",
        "    my_file_1 = UPLOAD_FOLDER + \"/\"+ filename\n",
        "    transcript= gpt.get_transcript(client, my_file_1, language=language )\n",
        "    data = {\"transcript\": transcript}\n",
        "    return data\n",
        "\n",
        "@app.route('/db_create', methods=['POST'])\n",
        "def db_create():\n",
        "    data = json.loads(request.data)\n",
        "    print(f'db_create data={data}')\n",
        "    knowledge_base_url = data['knowledge_base_url']\n",
        "    ba = data['ba']\n",
        "    BA = ba\n",
        "    KNOWLEDGE_BASE_URL = tls.get_google_url(knowledge_base_url)\n",
        "    print(f'KNOWLEDGE_BASE_URL={KNOWLEDGE_BASE_URL}')\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    knowledge_base_text = tls.load_document_text(KNOWLEDGE_BASE_URL)\n",
        "    db, ar_db_file_name, ar_chunk_num = dbt.create_db(ba, knowledge_base_text, DB_DIR_NAME, CHUNK_SIZE, embeddings)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFNJTcCrEMRq"
      },
      "outputs": [],
      "source": [
        "app.run(port=port_no)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cEvCe2m8MMY"
      },
      "source": [
        "# Вопросы и пожелания сюда:\n",
        " https://t.me/AiExp01"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}